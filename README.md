# üß† Proyecto: Extracci√≥n y Visualizaci√≥n de Informaci√≥n sobre Ciencia de Datos  

## üìã Descripci√≥n General  
Este proyecto realiza un **proceso completo de Web Scraping, Limpieza de Texto, ETL y Visualizaci√≥n de Datos**, con el objetivo de **extraer informaci√≥n relevante sobre Ciencia de Datos desde distintas fuentes web** y **representarla visualmente mediante una nube de palabras y un gr√°fico de frecuencias**.  

El flujo del an√°lisis sigue una estructura **ETL (Extract, Transform, Load)**:  
1. **Extracci√≥n** de texto desde m√∫ltiples URLs (IBM, Tableau, Wikipedia).  
2. **Transformaci√≥n** mediante tokenizaci√≥n, limpieza ling√º√≠stica y eliminaci√≥n de *stopwords*.  
3. **Carga y visualizaci√≥n** final en un **reporte PDF automatizado** con dos gr√°ficos generados en Python.  

---

## üöÄ Objetivo del Proyecto  
Aprender de forma pr√°ctica y **aut√≥noma** c√≥mo realizar un flujo de trabajo real de an√°lisis textual en Ciencia de Datos, incluyendo:  

- Web scraping intuitivo.  
- Procesamiento y limpieza de texto.  
- Generaci√≥n de una nube de palabras reproducible.  
- Visualizaci√≥n de las palabras m√°s frecuentes.  
- Exportaci√≥n autom√°tica a PDF para reportes profesionales.  

---
üìÅ proyecto_wordcloud/
‚îÇ
‚îú‚îÄ‚îÄ script_wordcloud.py          # C√≥digo principal del an√°lisis
‚îú‚îÄ‚îÄ nube_palabras.png            # Nube de palabras generada
‚îú‚îÄ‚îÄ grafico_frecuencia.png       # Gr√°fico de top 10 palabras
‚îú‚îÄ‚îÄ reporte_visual.pdf           # Reporte final exportado
‚îî‚îÄ‚îÄ README.md                    # Documentaci√≥n del proyecto
---

## üß∞ Tecnolog√≠as y Librer√≠as Utilizadas  

| Etapa | Librer√≠as / Herramientas |
|-------|---------------------------|
| Web Scraping | `requests`, `BeautifulSoup` |
| Procesamiento de Texto | `re`, `nltk`, `collections.Counter` |
| Visualizaci√≥n | `matplotlib`, `wordcloud` |
| Reporte Automatizado | `fpdf` |
| Entorno de Trabajo | Spyder (Python IDE) |

---

## üß© Flujo del Proceso  

### 1Ô∏è‚É£ Extracci√≥n  
Se recopilan textos desde URLs de referencia en ciencia de datos e inteligencia artificial:  
- [Tableau - Data Science](https://www.tableau.com/es-es/data-insights/data-science)  
- [IBM - Data Science](https://www.ibm.com/es-es/topics/data-science)  
- [Wikipedia - Inteligencia Artificial](https://es.wikipedia.org/wiki/Inteligencia_artificial)  
- entre otras.  

El texto de cada sitio se obtiene con `BeautifulSoup` y se acumula para su posterior an√°lisis.  

### 2Ô∏è‚É£ Transformaci√≥n (Limpieza y Tokenizaci√≥n)  
- Tokenizaci√≥n del texto en palabras.  
- Eliminaci√≥n de signos, n√∫meros y *stopwords* (en espa√±ol e ingl√©s).  
- Filtrado adicional de palabras irrelevantes o redundantes.  

### 3Ô∏è‚É£ Carga y Visualizaci√≥n  
- Se genera una **nube de palabras (WordCloud)** con `random_state=53` para garantizar **reproducibilidad** visual.  
- Se crea un **gr√°fico de barras** con las 10 palabras m√°s frecuentes.  

### 4Ô∏è‚É£ Reporte Automatizado (PDF)  
Ambas visualizaciones se exportan en un **reporte visual** (`reporte_visual.pdf`) que incluye:  
- T√≠tulo con fecha del d√≠a.  
- Imagen de la nube de palabras.  
- Gr√°fico de frecuencia de t√©rminos.  

---

## üìä Ejemplo de Resultados  

### ü©µ Nube de Palabras  
Representa los t√©rminos m√°s frecuentes en los textos de Ciencia de Datos.  

### ü©µ Gr√°fico de Frecuencia  
Muestra las **10 palabras m√°s mencionadas**, reflejando los conceptos dominantes en las fuentes analizadas.  

### ü©µ Reporte PDF  
El resultado final es un **reporte autom√°tico y portable** que consolida los hallazgos visuales del an√°lisis.  

---

## üí° Aprendizajes Clave  
- Implementar **Web Scraping de forma intuitiva** para extraer informaci√≥n √∫til de la web.  
- Aplicar **procesos ETL** al tratamiento de texto.  
- Generar **visualizaciones reproducibles** (controlando la aleatoriedad con `random_state`).  
- Crear **reportes visuales automatizados** para comunicar resultados.  

---

## ‚öôÔ∏è Requisitos de Ejecuci√≥n  

Instalar las dependencias necesarias (puedes usar un entorno virtual):  

```bash
- pip install requests beautifulsoup4 matplotlib wordcloud nltk fpdf
- import nltk
nltk.download("stopwords")


